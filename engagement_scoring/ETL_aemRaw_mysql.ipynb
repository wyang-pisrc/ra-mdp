{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2aa7fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T16:34:57.779579Z",
     "start_time": "2022-12-15T16:34:57.770306Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0873b716",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T15:09:36.748295Z",
     "start_time": "2022-12-15T15:09:36.732618Z"
    }
   },
   "source": [
    "### utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ad45a51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T19:27:35.573216Z",
     "start_time": "2022-12-16T19:27:33.455362Z"
    }
   },
   "outputs": [],
   "source": [
    "from contentScoreShareUtils import * \n",
    "\n",
    "def add_timestamp_columns(stage1_raw):\n",
    "    stage1_raw[\"date\"] = stage1_raw[\"DateTime_UTC\"].apply(lambda x: x[0:10]) ## 2022-11-01 00:00:02-06:00\n",
    "    stage1_raw[\"hour\"] = stage1_raw[\"DateTime_UTC\"].apply(lambda x: x[11:13]) ## 2022-11-01 00:00:02-06:00\n",
    "    # stage1_raw[\"minute\"] = datetime.apply(lambda x: x.minute)\n",
    "    return stage1_raw;\n",
    "\n",
    "def convert_schema(stage1_raw):\n",
    "    columns = pd.io.json.build_table_schema(stage1_raw)\n",
    "    df_schema = {col[\"name\"]:dtype_convert(col[\"type\"]) for col in columns[\"fields\"]}\n",
    "    return df_schema\n",
    "\n",
    "def dtype_convert(pandas_type):\n",
    "    type = \"Unknown\"\n",
    "    if pandas_type == \"integer\":\n",
    "        type = INTEGER()\n",
    "    elif pandas_type == \"string\":\n",
    "        type = VARCHAR(255)\n",
    "    elif pandas_type == \"number\":\n",
    "        type = FLOAT(asdecimal=True)\n",
    "    elif pandas_type == \"boolean\":\n",
    "        type = BOOLEAN()\n",
    "    return type\n",
    "\n",
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "def insert_with_progress(df, connection, table_name, insert_mode=False, dtype=None):\n",
    "    chunksize = int(len(df) / 100) # 10%\n",
    "    with tqdm(total=len(df)) as pbar:\n",
    "        for i, cdf in enumerate(chunker(df, chunksize)):\n",
    "            replace = \"replace\" if (i == 0 and insert_mode is False) else \"append\"\n",
    "            cdf.to_sql(con=connection, name=table_name, dtype=dtype, if_exists=replace, index=False)\n",
    "            pbar.update(chunksize)\n",
    "                    \n",
    "def load_csv_iter(glob_pattern=\"./target_mcvisid/*.csv\"):\n",
    "    files = sorted([file for file in glob(glob_pattern) if \"aemRaw_keyColumns_2022\" in file])\n",
    "    for file in files:\n",
    "        current = pd.read_csv(file)\n",
    "        print(\"current file, \", file)\n",
    "        yield file, current\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df49f55",
   "metadata": {},
   "source": [
    "### key filters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7553e476",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T19:27:35.582334Z",
     "start_time": "2022-12-16T19:27:35.574799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.rockwellautomation.com'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def url_clean(x):\n",
    "    x = re.sub(',|;', \"\", x) # clean special symbol\n",
    "    x = re.sub(\"(#|.page|.aspx|.js|.php|adfs).*\", \"\", x)  # clean tailing start with\n",
    "    # x = re.sub(\"details.[\\w-]*\",\"details.{ID}\", x) # grouping product details\n",
    "    x = re.sub(\"com.cn\", \"com\", x) # replace china area website URL\n",
    "    # x = re.sub(\"%20\", \" \", x) # keep URL encoding\n",
    "    \n",
    "    # grouping different language\n",
    "    x = re.sub(\"/$|(\\.html)$|/[a-zA-Z]{2}$\", \"\", x)  # remove html, etc /\n",
    "    x = re.sub(\"/(global|go)/\", \"/\", x)  \n",
    "    x = re.sub(\".com/[a-zA-Z]{2,3}/\", \".com/\", x)  \n",
    "    x = re.sub(\"/[a-zA-Z]{2}[-_][a-zA-Z]{2,3}$\", \"\", x)  # grouping homepage\n",
    "    x = re.sub(\"/[a-zA-Z]{2}[-_][a-zA-Z]{2}[-_][a-zA-Z]{2}$\", \"\", x)  # grouping search page\n",
    "    x = re.sub(\"/[a-zA-Z]{2}[-_][a-zA-Z]{2,3}/|/[a-zA-Z]{2}/\", \"/\", x)  # grouping different language\n",
    "    \n",
    "    return x\n",
    "\n",
    "def url_filter(url_maps):\n",
    "    url_maps = url_maps[(~url_maps[\"PageURL\"].str.contains(\"file://.+\")) & (url_maps[\"PageURL\"].str.startswith(\"https://www.rockwellautomation\"))] \n",
    "#     url_maps.query(\"('file://.+' not in PageURL) or https://www.rockwellautomation in PageURL\") # query mode\n",
    "    return url_maps\n",
    "    \n",
    "# x = \"https://www.rockwellautomation.com/ja-jp/company/events/in-person-events/archive.html\"\n",
    "# x = \"https://www.rockwellautomation.com/ja-jp/company/events/in-person-events/search/en-us-ab\"\n",
    "# x = \"https://www.rockwellautomation.com/zh_TW\"\n",
    "# x = \"https://www.rockwellautomation.com/hu-huhtml\"\n",
    "# x = \"https://www.rockwellautomation.com/en-us/products/details.700-N400A1.html).html#adfdasf\"\n",
    "# x = \"https://www.rockwellautomation.com/rockwellautomation/support/pcdc.page%7D%7D%7D/f0/fs20\"\n",
    "# x = \"https://www.rockwellautomation.com/ja/fa.pagedfsdfa\"\n",
    "# x = \"https://www.rockwellautomation.com/chl/overview.page\"\n",
    "# x = \"https://www.rockwellautomation.com/adfs/oauth2/authorize\"\n",
    "x = \"https://www.rockwellautomation.com/en-nz/\"\n",
    "url_clean(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7951c3a9",
   "metadata": {},
   "source": [
    "### start ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eb70de6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T21:45:20.630913Z",
     "start_time": "2022-12-15T21:45:20.616552Z"
    }
   },
   "outputs": [],
   "source": [
    "VERSION = \"v1.2\"\n",
    "table_name = \"stage1_raw\" + \"_\" + VERSION\n",
    "\n",
    "refresh_table = True\n",
    "mydb = create_engine('mysql+pymysql://rockwell:%s@localhost:3306/page_scoring' % quote('rockwell'))\n",
    "testing = False\n",
    "folder_dir = './aem_raw/'\n",
    "\n",
    "schema = {'index': INTEGER(),\n",
    " 'SessionVisitorId': VARCHAR(length=255),\n",
    " 'VisitPageNumber': INTEGER(),\n",
    " 'VisitNumber': INTEGER(),\n",
    " 'NewVisit': BOOLEAN(),\n",
    " 'EventList': VARCHAR(length=511),\n",
    " 'DateTime_UTC': VARCHAR(length=255),\n",
    " 'PageURL': VARCHAR(length=255),\n",
    " 'VisitReferrer': VARCHAR(length=255),\n",
    " 'VisitReferrerType': INTEGER(),\n",
    " 'VisitorDomain': VARCHAR(length=255),\n",
    " 'External_Audience': VARCHAR(length=255),\n",
    " 'External_AudienceSegment': VARCHAR(length=255),\n",
    " 'External_Industry': VARCHAR(length=255),\n",
    " 'External_Website': VARCHAR(length=255),\n",
    " 'EloquaContactId': VARCHAR(length=255),\n",
    " 'EloquaGUID': FLOAT(asdecimal=True),\n",
    " 'mcvisid': VARCHAR(length=255),\n",
    " 'GeoCity': VARCHAR(length=255),\n",
    " 'GeoCountry': VARCHAR(length=255),\n",
    " 'GeoRegion': VARCHAR(length=255),\n",
    " 'PDFurl': VARCHAR(length=255),\n",
    " 'PDFpagecount': FLOAT(asdecimal=True),\n",
    " 'BingeId': VARCHAR(length=255),\n",
    " 'BingeCriticalScore': FLOAT(asdecimal=True),\n",
    " 'BingeScoredAssetPath': VARCHAR(length=255),\n",
    " 'BingeScoredAssetScore': FLOAT(asdecimal=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1d2bb6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T22:15:41.468351Z",
     "start_time": "2022-12-15T21:45:20.631711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current file,  ./aem_raw/aemRaw_keyColumns_20220401-20220415.csv\n",
      "{'index': INTEGER(), 'SessionVisitorId': VARCHAR(length=255), 'VisitPageNumber': INTEGER(), 'VisitNumber': INTEGER(), 'NewVisit': BOOLEAN(), 'EventList': VARCHAR(length=511), 'DateTime_UTC': VARCHAR(length=255), 'PageURL': VARCHAR(length=255), 'VisitReferrer': VARCHAR(length=255), 'VisitReferrerType': INTEGER(), 'VisitorDomain': VARCHAR(length=255), 'External_Audience': VARCHAR(length=255), 'External_AudienceSegment': VARCHAR(length=255), 'External_Industry': VARCHAR(length=255), 'External_Website': VARCHAR(length=255), 'EloquaContactId': VARCHAR(length=255), 'EloquaGUID': FLOAT(asdecimal=True), 'mcvisid': VARCHAR(length=255), 'GeoCity': VARCHAR(length=255), 'GeoCountry': VARCHAR(length=255), 'GeoRegion': VARCHAR(length=255), 'PDFurl': VARCHAR(length=255), 'PDFpagecount': FLOAT(asdecimal=True), 'BingeId': VARCHAR(length=255), 'BingeCriticalScore': FLOAT(asdecimal=True), 'BingeScoredAssetPath': VARCHAR(length=255), 'BingeScoredAssetScore': FLOAT(asdecimal=True)}\n",
      "original raw rows: 5584815\n",
      "Drop irrelevant mcvisid (testing emails) with rows: 296510\n",
      "start dedup with considering only unique records in hours granularity...\n",
      "Drop duplicate rows by [\"mcvisid\",\"date\", \"hour\", \"PageURL\"]: 3946964 ratio 0.7463571030793421\n",
      "Drop irrelevant PageURL (by inner join) with rows: 34676\n",
      "stage1_raw: keep mcvisid rows:  1306665\n",
      "stage1_raw: keep unique mcvisid:  639212\n",
      "stage1_raw: keep unique pageURL:  212245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1319666it [01:32, 14304.03it/s]                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table stage1_raw insert successfully.\n",
      "current file,  ./aem_raw/aemRaw_keyColumns_20220415-20220430.csv\n",
      "original raw rows: 5235230\n",
      "Drop irrelevant mcvisid (testing emails) with rows: 276607\n",
      "start dedup with considering only unique records in hours granularity...\n",
      "Drop duplicate rows by [\"mcvisid\",\"date\", \"hour\", \"PageURL\"]: 3563994 ratio 0.7187467165783726\n",
      "Drop irrelevant PageURL (by inner join) with rows: 52367\n",
      "stage1_raw: keep mcvisid rows:  1342262\n",
      "stage1_raw: keep unique mcvisid:  689118\n",
      "stage1_raw: keep unique pageURL:  263823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1355622it [01:38, 13695.28it/s]                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table stage1_raw insert successfully.\n",
      "current file,  ./aem_raw/aemRaw_keyColumns_20220501-20220515.csv\n",
      "original raw rows: 5495277\n",
      "Drop irrelevant mcvisid (testing emails) with rows: 351812\n",
      "start dedup with considering only unique records in hours granularity...\n",
      "Drop duplicate rows by [\"mcvisid\",\"date\", \"hour\", \"PageURL\"]: 4163824 ratio 0.8095367616966384\n",
      "Drop irrelevant PageURL (by inner join) with rows: 36675\n",
      "stage1_raw: keep mcvisid rows:  942966\n",
      "stage1_raw: keep unique mcvisid:  366467\n",
      "stage1_raw: keep unique pageURL:  24130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "952329it [01:09, 13750.62it/s]                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table stage1_raw insert successfully.\n",
      "current file,  ./aem_raw/aemRaw_keyColumns_20220515-20220531.csv\n",
      "original raw rows: 6413570\n",
      "Drop irrelevant mcvisid (testing emails) with rows: 398732\n",
      "start dedup with considering only unique records in hours granularity...\n",
      "Drop duplicate rows by [\"mcvisid\",\"date\", \"hour\", \"PageURL\"]: 4901685 ratio 0.8149321727368218\n",
      "Drop irrelevant PageURL (by inner join) with rows: 39072\n",
      "stage1_raw: keep mcvisid rows:  1074081\n",
      "stage1_raw: keep unique mcvisid:  408249\n",
      "stage1_raw: keep unique pageURL:  23598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1084740it [01:15, 14424.51it/s]                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table stage1_raw insert successfully.\n",
      "current file,  ./aem_raw/aemRaw_keyColumns_20220601-20220615.csv\n",
      "original raw rows: 5490207\n",
      "Drop irrelevant mcvisid (testing emails) with rows: 331552\n",
      "start dedup with considering only unique records in hours granularity...\n",
      "Drop duplicate rows by [\"mcvisid\",\"date\", \"hour\", \"PageURL\"]: 4339802 ratio 0.8412661827550011\n",
      "Drop irrelevant PageURL (by inner join) with rows: 39825\n",
      "stage1_raw: keep mcvisid rows:  779028\n",
      "stage1_raw: keep unique mcvisid:  296519\n",
      "stage1_raw: keep unique pageURL:  20613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "786790it [00:55, 14162.39it/s]                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table stage1_raw insert successfully.\n",
      "current file,  ./aem_raw/aemRaw_keyColumns_20220615-20220630.csv\n",
      "original raw rows: 2997171\n",
      "Drop irrelevant mcvisid (testing emails) with rows: 196137\n",
      "start dedup with considering only unique records in hours granularity...\n",
      "Drop duplicate rows by [\"mcvisid\",\"date\", \"hour\", \"PageURL\"]: 2624213 ratio 0.9368729547731303\n",
      "Drop irrelevant PageURL (by inner join) with rows: 43507\n",
      "stage1_raw: keep mcvisid rows:  133314\n",
      "stage1_raw: keep unique mcvisid:  74084\n",
      "stage1_raw: keep unique pageURL:  165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "134633it [00:09, 14043.30it/s]                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table stage1_raw insert successfully.\n",
      "current file,  ./aem_raw/aemRaw_keyColumns_20220701-20220715.csv\n",
      "original raw rows: 4322589\n",
      "Drop irrelevant mcvisid (testing emails) with rows: 229350\n",
      "start dedup with considering only unique records in hours granularity...\n",
      "Drop duplicate rows by [\"mcvisid\",\"date\", \"hour\", \"PageURL\"]: 3592882 ratio 0.8777601307912878\n",
      "Drop irrelevant PageURL (by inner join) with rows: 38013\n",
      "stage1_raw: keep mcvisid rows:  462344\n",
      "stage1_raw: keep unique mcvisid:  205315\n",
      "stage1_raw: keep unique pageURL:  13698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "466923it [00:32, 14333.95it/s]                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table stage1_raw insert successfully.\n",
      "current file,  ./aem_raw/aemRaw_keyColumns_20220715-20220731.csv\n",
      "original raw rows: 3680306\n",
      "Drop irrelevant mcvisid (testing emails) with rows: 209329\n",
      "start dedup with considering only unique records in hours granularity...\n",
      "Drop duplicate rows by [\"mcvisid\",\"date\", \"hour\", \"PageURL\"]: 3087756 ratio 0.8895927573129986\n",
      "Drop irrelevant PageURL (by inner join) with rows: 50801\n",
      "stage1_raw: keep mcvisid rows:  332420\n",
      "stage1_raw: keep unique mcvisid:  217731\n",
      "stage1_raw: keep unique pageURL:  3788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "335724it [00:22, 15230.32it/s]                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table stage1_raw insert successfully.\n",
      "current file,  ./aem_raw/aemRaw_keyColumns_20220801-20220815.csv\n",
      "original raw rows: 4565584\n",
      "Drop irrelevant mcvisid (testing emails) with rows: 225676\n",
      "start dedup with considering only unique records in hours granularity...\n",
      "Drop duplicate rows by [\"mcvisid\",\"date\", \"hour\", \"PageURL\"]: 3708392 ratio 0.8544863162997925\n",
      "Drop irrelevant PageURL (by inner join) with rows: 36363\n",
      "stage1_raw: keep mcvisid rows:  595153\n",
      "stage1_raw: keep unique mcvisid:  305846\n",
      "stage1_raw: keep unique pageURL:  15452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601051it [00:40, 14817.02it/s]                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table stage1_raw insert successfully.\n",
      "current file,  ./aem_raw/aemRaw_keyColumns_20220815-20220831.csv\n",
      "original raw rows: 8746625\n",
      "Drop irrelevant mcvisid (testing emails) with rows: 449514\n",
      "start dedup with considering only unique records in hours granularity...\n",
      "Drop duplicate rows by [\"mcvisid\",\"date\", \"hour\", \"PageURL\"]: 7084384 ratio 0.8538374381155079\n",
      "Drop irrelevant PageURL (by inner join) with rows: 26845\n",
      "stage1_raw: keep mcvisid rows:  1185882\n",
      "stage1_raw: keep unique mcvisid:  499031\n",
      "stage1_raw: keep unique pageURL:  23965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1197658it [01:26, 13775.11it/s]                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table stage1_raw insert successfully.\n",
      "current file,  ./aem_raw/aemRaw_keyColumns_20220901-20220915.csv\n",
      "original raw rows: 7084004\n",
      "Drop irrelevant mcvisid (testing emails) with rows: 383296\n",
      "start dedup with considering only unique records in hours granularity...\n",
      "Drop duplicate rows by [\"mcvisid\",\"date\", \"hour\", \"PageURL\"]: 5736282 ratio 0.8560710301060723\n",
      "Drop irrelevant PageURL (by inner join) with rows: 7516\n",
      "stage1_raw: keep mcvisid rows:  956910\n",
      "stage1_raw: keep unique mcvisid:  416858\n",
      "stage1_raw: keep unique pageURL:  22370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "966469it [01:08, 14047.64it/s]                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table stage1_raw insert successfully.\n",
      "current file,  ./aem_raw/aemRaw_keyColumns_20220915-20220930.csv\n",
      "original raw rows: 7222517\n",
      "Drop irrelevant mcvisid (testing emails) with rows: 418310\n",
      "start dedup with considering only unique records in hours granularity...\n",
      "Drop duplicate rows by [\"mcvisid\",\"date\", \"hour\", \"PageURL\"]: 5623244 ratio 0.8264363503344327\n",
      "Drop irrelevant PageURL (by inner join) with rows: 12230\n",
      "stage1_raw: keep mcvisid rows:  1168733\n",
      "stage1_raw: keep unique mcvisid:  481827\n",
      "stage1_raw: keep unique pageURL:  23283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1180387it [01:22, 14356.97it/s]                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table stage1_raw insert successfully.\n",
      "current file,  ./aem_raw/aemRaw_keyColumns_20221001-20221015.csv\n",
      "original raw rows: 6240070\n",
      "Drop irrelevant mcvisid (testing emails) with rows: 370816\n",
      "start dedup with considering only unique records in hours granularity...\n",
      "Drop duplicate rows by [\"mcvisid\",\"date\", \"hour\", \"PageURL\"]: 4771402 ratio 0.8129486302688553\n",
      "Drop irrelevant PageURL (by inner join) with rows: 11134\n",
      "stage1_raw: keep mcvisid rows:  1086718\n",
      "stage1_raw: keep unique mcvisid:  445014\n",
      "stage1_raw: keep unique pageURL:  23098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097567it [01:17, 14164.83it/s]                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table stage1_raw insert successfully.\n",
      "current file,  ./aem_raw/aemRaw_keyColumns_20221015-20221031.csv\n",
      "original raw rows: 6988682\n",
      "Drop irrelevant mcvisid (testing emails) with rows: 344546\n",
      "start dedup with considering only unique records in hours granularity...\n",
      "Drop duplicate rows by [\"mcvisid\",\"date\", \"hour\", \"PageURL\"]: 5570933 ratio 0.838473655566352\n",
      "Drop irrelevant PageURL (by inner join) with rows: 10378\n",
      "stage1_raw: keep mcvisid rows:  1062825\n",
      "stage1_raw: keep unique mcvisid:  447921\n",
      "stage1_raw: keep unique pageURL:  23141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1073428it [01:15, 14262.96it/s]                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table stage1_raw insert successfully.\n",
      "current file,  ./aem_raw/aemRaw_keyColumns_20221101-20221115.csv\n",
      "original raw rows: 7904562\n",
      "Drop irrelevant mcvisid (testing emails) with rows: 411787\n",
      "start dedup with considering only unique records in hours granularity...\n",
      "Drop duplicate rows by [\"mcvisid\",\"date\", \"hour\", \"PageURL\"]: 6329490 ratio 0.8447457717601289\n",
      "Drop irrelevant PageURL (by inner join) with rows: 14374\n",
      "stage1_raw: keep mcvisid rows:  1148911\n",
      "stage1_raw: keep unique mcvisid:  462094\n",
      "stage1_raw: keep unique pageURL:  25632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1160389it [01:18, 14719.28it/s]                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table stage1_raw insert successfully.\n",
      "current file,  ./aem_raw/aemRaw_keyColumns_20221115-20221130.csv\n",
      "original raw rows: 7898931\n",
      "Drop irrelevant mcvisid (testing emails) with rows: 344666\n",
      "start dedup with considering only unique records in hours granularity...\n",
      "Drop duplicate rows by [\"mcvisid\",\"date\", \"hour\", \"PageURL\"]: 6389764 ratio 0.8458485372170556\n",
      "Drop irrelevant PageURL (by inner join) with rows: 8971\n",
      "stage1_raw: keep mcvisid rows:  1155530\n",
      "stage1_raw: keep unique mcvisid:  469041\n",
      "stage1_raw: keep unique pageURL:  26315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1167055it [01:20, 14507.73it/s]                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table stage1_raw insert successfully.\n"
     ]
    }
   ],
   "source": [
    "# aem_raw = load_csv_batches(glob_pattern=\"./aem_raw/*.csv\", num=None, keep=\"last\", iterator=False)\n",
    "aem_raws = load_csv_iter(glob_pattern=folder_dir+\"*.csv\")\n",
    "\n",
    "if refresh_table is True:\n",
    "    with mydb.connect() as connection:\n",
    "        connection.execute(f\"\"\"DROP TABLE IF EXISTS {table_name};\"\"\")\n",
    "\n",
    "### preload data, could update as a query\n",
    "email_mcvisid = pd.read_csv(\"mcvisid_elqid_email_all.csv\")\n",
    "email_mcvisid, drop_mcvisid = email_cleanup(email_mcvisid, \"EmailAddress\")\n",
    "positive_mcvisid = email_mcvisid[\"mcvisid\"].drop_duplicates() ## all along the past, if mcvisid existed with corresponding elqid, then it is positive sigal\n",
    "\n",
    "\n",
    "\n",
    "logs = []\n",
    "for idx, (file, aem_raw) in enumerate(aem_raws):\n",
    "    log = []\n",
    "    log.append(file)\n",
    "    stage1_raw = aem_raw #.dropna(subset=[\"BingeScoredAssetPath\"]).reset_index(drop=True)\n",
    "    if idx < 1:\n",
    "        df_schema = convert_schema(stage1_raw) if not schema else schema\n",
    "        print(df_schema)\n",
    "    row1 = stage1_raw.shape[0]\n",
    "    print(f\"original raw rows: {row1}\")\n",
    "    log.append(row1)\n",
    "\n",
    "    stage1_raw = stage1_raw[~stage1_raw[\"mcvisid\"].isin(drop_mcvisid[\"mcvisid\"])] # drop irrelevant mcvisid\n",
    "    row2 = stage1_raw.shape[0]\n",
    "    print(f\"Drop irrelevant mcvisid (testing emails) with rows: {row1 - row2}\")\n",
    "    log.append(row1 - row2)\n",
    "\n",
    "    ## deduplicate with hour granularity\n",
    "    print(\"start dedup with considering only unique records in hours granularity...\")\n",
    "    stage1_raw = add_timestamp_columns(stage1_raw)    \n",
    "    stage1_raw = stage1_raw.drop_duplicates(subset=[\"mcvisid\",\"date\", \"hour\", \"PageURL\"], keep=\"first\")\n",
    "    row3 = stage1_raw.shape[0]\n",
    "    print(f\"\"\"Drop duplicate rows by [\"mcvisid\",\"date\", \"hour\", \"PageURL\"]: {row2 - row3} ratio {(row2 - row3)/row2}\"\"\")\n",
    "    log.append(row2 - row3)\n",
    "    log.append((row2 - row3)/row2)\n",
    "\n",
    "    ## get clean PageURL and drop irrelevant PageURL - inner join to drop unmatched rows\n",
    "    url_maps = url_filter(stage1_raw[[\"PageURL\"]].drop_duplicates())\n",
    "    url_maps[\"clean_PageURL\"] = url_maps[\"PageURL\"].apply(lambda x: url_clean(x))\n",
    "    # s = url_maps[url_maps[\"PageURL\"].str.contains(\"details\")].sample(100)\n",
    "    stage1_raw = stage1_raw.merge(url_maps, on=\"PageURL\")\n",
    "    row4 = stage1_raw.shape[0]\n",
    "    print(f\"Drop irrelevant PageURL (by inner join) with rows: {row3 - row4}\")\n",
    "    log.append(row3 - row4)\n",
    "\n",
    "    ## create labels\n",
    "    stage1_raw[\"label\"] = stage1_raw[\"mcvisid\"].isin(positive_mcvisid) # mark pos and neg mcvisid\n",
    "    row5 = stage1_raw.shape[0]\n",
    "    print(\"stage1_raw: keep mcvisid rows: \", row5)\n",
    "    print(\"stage1_raw: keep unique mcvisid: \", stage1_raw[\"mcvisid\"].unique().shape[0])\n",
    "    print(\"stage1_raw: keep unique pageURL: \", stage1_raw[\"clean_PageURL\"].unique().shape[0])\n",
    "    log.append(row5)\n",
    "    log.append(stage1_raw[\"mcvisid\"].unique().shape[0])\n",
    "    log.append(stage1_raw[\"clean_PageURL\"].unique().shape[0])\n",
    "    \n",
    "    try:\n",
    "        insert_with_progress(stage1_raw, mydb, table_name=table_name, insert_mode=True, dtype=df_schema)\n",
    "    except ValueError as vx:\n",
    "        print(vx)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "    else:\n",
    "        print(\"Table %s insert successfully.\" % table_name)\n",
    "    \n",
    "    logs.append(log)    \n",
    "    if testing is True:\n",
    "        break\n",
    "\n",
    "with mydb.connect() as connection:\n",
    "    connection.execute(f\"\"\"ALTER TABLE {table_name} ADD KEY(mcvisid(255));\"\"\")\n",
    "    connection.execute(f\"\"\"ALTER TABLE {table_name} ADD KEY(EloquaContactId(255));\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88066d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece017d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T22:15:41.530594Z",
     "start_time": "2022-12-15T22:15:41.475641Z"
    }
   },
   "outputs": [],
   "source": [
    "logs_df = pd.DataFrame(logs, columns=[\n",
    "            \"file\",\n",
    "            \"original raw rows\",\n",
    "            \"Drop irrelevant mcvisid (testing emails) with rows\",\n",
    "            \"Drop duplicate rows by ['mcvisid','date', 'hour', 'PageURL']\",\n",
    "            \"Drop duplicate rows by ['mcvisid','date', 'hour', 'PageURL'] ratio\",\n",
    "            \"Drop irrelevant PageURL (by inner join) with rows\",\n",
    "            \"After ETL keep mcvisid rows\",\n",
    "            \"After ETL keep unique mcvisid\",\n",
    "            \"After ETL keep unique pageURL\",])\n",
    "\n",
    "logs_df.to_excel(f\"{table_name}_table_ETL_logs.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19ab4e65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T22:15:41.822223Z",
     "start_time": "2022-12-15T22:15:41.531668Z"
    }
   },
   "outputs": [],
   "source": [
    "url_maps[\"isChanged\"] = url_maps[\"clean_PageURL\"]!=url_maps[\"PageURL\"]\n",
    "url_maps.to_csv(\"clean_PageURL_checking.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b1127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4802c38d",
   "metadata": {},
   "source": [
    "### store in local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "681c6527",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T22:15:41.825590Z",
     "start_time": "2022-12-15T22:15:41.823134Z"
    }
   },
   "outputs": [],
   "source": [
    "usecols = [\n",
    "    \"mcvisid\", \"clean_PageURL\", \"label\", \"PDFurl\", \"BingeScoredAssetPath\", \"BingeId\", \"date\", \"hour\",\n",
    "    \"VisitReferrer\", \"VisitorDomain\", 'External_Audience',\n",
    "    'External_AudienceSegment', 'External_Industry', 'External_Website',\n",
    "    \"EloquaContactId\", \"PageURL\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8da423a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T22:23:17.684648Z",
     "start_time": "2022-12-15T22:15:41.826617Z"
    }
   },
   "outputs": [],
   "source": [
    "# table_name = \"stage1_raw\"\n",
    "mydb = create_engine('mysql+pymysql://rockwell:%s@localhost:3306/page_scoring' % quote('rockwell'))\n",
    "    \n",
    "with mydb.connect() as connection:\n",
    "    stage1_raw_2 = pd.read_sql_query(f'SELECT {\", \".join(usecols)} FROM {table_name}',connection)\n",
    "    \n",
    "stage1_raw_2.to_csv(\"stage1_raw_v1.2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4b63b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492ce39f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
